{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# read both the images of the face and the glasses\n",
    "image = cv2.imread('Jamie_Before.jpg')\n",
    "glass_img = cv2.imread('glasses.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "centers = []\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# iterating over the face detected\n",
    "for (x, y, w, h) in faces:\n",
    "\n",
    "    # create two Regions of Interest.\n",
    "    roi_gray = gray[y:y + h, x:x + w]\n",
    "    roi_color = image[y:y + h, x:x + w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "    # Store the coordinates of eyes in the image to the 'center' array\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        centers.append((x + int(ex + 0.5 * ew), y + int(ey + 0.5 * eh)))\n",
    "\n",
    "if len(centers) > 0:\n",
    "    # change the given value of 2.15 according to the size of the detected face\n",
    "    glasses_width = 2.5 * abs(centers[1][0] - centers[0][0])\n",
    "    overlay_img = np.ones(image.shape, np.uint8) * 255\n",
    "    h, w = glass_img.shape[:2]\n",
    "    scaling_factor = glasses_width / w\n",
    "\n",
    "    overlay_glasses = cv2.resize(glass_img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    x = centers[0][0] if centers[0][0] < centers[1][0] else centers[1][0]\n",
    "\n",
    "    # The x and y variables below depend upon the size of the detected face.\n",
    "    x -= 0.26 * overlay_glasses.shape[1]\n",
    "    y += 0.85 * overlay_glasses.shape[0]\n",
    "\n",
    "    # Slice the height, width of the overlay image.\n",
    "    h, w = overlay_glasses.shape[:2]\n",
    "    overlay_img[int(y):int(y + h), int(x):int(x + w)] = overlay_glasses\n",
    "\n",
    "    # Create a mask and generate it's inverse.\n",
    "    gray_glasses = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(gray_glasses, 110, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    temp = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    temp2 = cv2.bitwise_and(overlay_img, overlay_img, mask=mask_inv)\n",
    "    final_img = cv2.add(temp, temp2)\n",
    "\n",
    "    # imS = cv2.resize(final_img, (1366, 768))\n",
    "    cv2.imshow('Lets wear Glasses', final_img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
